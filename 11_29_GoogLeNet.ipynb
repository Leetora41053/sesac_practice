{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3df9sIjbxK45JopDQIuWB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leetora41053/sesac_practice/blob/main/11_29_GoogLeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxCaAULAqVrH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#이전 레이어 input = (192, 100, 100)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1):\n",
        "    super(ConvBlock, self).__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                  kernel_size=kernel_size, padding=padding, stride=stride)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.relu(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#axis 질문\n",
        "one_inception = torch.concat([out_branch1, out_branch2, out_branch3, out_branch4], axis=0)\n",
        "print"
      ],
      "metadata": {
        "id": "7d3RR3jfs1JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "C = 192\n",
        "H = 100\n",
        "W = 100\n",
        "input_tensor = torch.randn(size= (C,H,W))\n",
        "\n",
        "branch1 = ConvBlock(in_channels=192, out_channels=64, kernel_size=1, padding=0, stride=1)\n",
        "out_branch1 = branch1.forward(input_tensor)\n",
        "\n",
        "branch2 = ConvBlock(in_channels=192, out_channels=128, kernel_size=3, padding=1, stride=1)\n",
        "out_branch2 = branch2.forward(input_tensor)\n",
        "\n",
        "branch3 = ConvBlock(in_channels=192, out_channels=32, kernel_size=5, padding=2, stride=1)\n",
        "out_branch3 = branch3.forward(input_tensor)\n",
        "\n",
        "branch4 = ConvBlock(in_channels=192, out_channels=192, kernel_size=3, padding=1, stride=1)\n",
        "out_branch4 = branch4.forward(input_tensor)\n",
        "\n",
        "out_inception = torch.concat([out_branch1, out_branch2, out_branch3, out_branch4],axis=0)\n",
        "\n",
        "print(out_branch1.shape)\n",
        "print(out_branch3.shape)\n",
        "print(out_branch2.shape)\n",
        "print(out_branch4.shape)\n",
        "print(out_inception.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCHW0nrBs8zv",
        "outputId": "b4f265bb-82b0-4881-81a6-de3bf4c28a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 100, 100])\n",
            "torch.Size([32, 100, 100])\n",
            "torch.Size([128, 100, 100])\n",
            "torch.Size([192, 100, 100])\n",
            "torch.Size([416, 100, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C,H,W  = 192, 100, 100\n",
        "\n",
        "input_tensor = torch.randn(size= (C,H,W))\n",
        "\n",
        "class InceptionNaive(nn.Module):\n",
        "  def __init__(self, in_channels, ch1x1, ch3x3, ch5x5):\n",
        "    super(InceptionNaive, self).__init__()\n",
        "\n",
        "    self.branch1 = ConvBlock(in_channels=192, out_channels=ch1x1, kernel_size=1, padding=0, stride=1)\n",
        "    self.branch2 = ConvBlock(in_channels=192, out_channels=ch3x3, kernel_size=3, padding=1, stride=1)\n",
        "    self.branch3 = ConvBlock(in_channels=192, out_channels=ch5x5, kernel_size=5, padding=2, stride=1)\n",
        "    self.branch4 = nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out_branch1 = self.branch1(x)\n",
        "    out_branch2 = self.branch2(x)\n",
        "    out_branch3 = self.branch3(x)\n",
        "    out_branch4 = self.branch4(x)\n",
        "\n",
        "    x = torch.concat([out_branch1, out_branch1, out_branch3, out_branch4],axis=0)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "  import torch\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "H, W = 100, 100\n",
        "channels = 192\n",
        "input_tensor = torch.randn(size=(BATCH_SIZE, channels, H, W))\n",
        "print(\"Input: \", input_tensor)\n",
        "\n",
        "inception = InceptionNaive(in_channels=192, c1x1=64, c3x3=128, ch5x5=32)\n",
        "output_tensor = inception(input_tensor)\n",
        "print(\"Output: \", output_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3xVkXoDu9L-Q",
        "outputId": "7f9393eb-cf2b-4404-fa67-14b014e66f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  tensor([[[[ 2.3937e-01, -1.0709e+00,  6.6390e-01,  ...,  1.0869e+00,\n",
            "           -9.4988e-01, -8.6603e-01],\n",
            "          [ 1.6344e+00, -1.5527e+00,  2.5795e-01,  ...,  5.9477e-01,\n",
            "            6.5516e-01,  8.4279e-01],\n",
            "          [-2.0245e-01,  3.9746e-01,  8.1168e-01,  ...,  4.3166e-01,\n",
            "           -1.2237e+00,  3.5803e-01],\n",
            "          ...,\n",
            "          [-8.0663e-01,  1.3480e+00, -1.0966e+00,  ..., -1.3911e+00,\n",
            "            1.2308e+00,  5.6291e-02],\n",
            "          [-2.2797e-01, -7.1013e-01, -2.0452e+00,  ...,  9.4463e-01,\n",
            "            1.0813e+00,  3.3887e-01],\n",
            "          [ 5.3722e-01,  8.5380e-01,  8.4262e-01,  ...,  1.7051e+00,\n",
            "           -2.4633e-01,  2.5979e-01]],\n",
            "\n",
            "         [[ 1.7710e+00,  2.3268e+00, -1.6571e+00,  ...,  1.6595e-01,\n",
            "            2.1745e-01,  1.3960e+00],\n",
            "          [ 2.4542e-01, -5.2668e-01, -1.7747e+00,  ...,  2.8551e-01,\n",
            "            5.1263e-01,  1.9071e+00],\n",
            "          [-6.1584e-01,  1.3218e+00,  3.4356e-01,  ..., -5.4978e-01,\n",
            "           -5.7903e-01, -2.8166e-01],\n",
            "          ...,\n",
            "          [ 1.2062e+00, -1.7085e+00, -8.5220e-02,  ..., -3.1252e-01,\n",
            "           -7.2857e-01,  1.0848e+00],\n",
            "          [-1.2611e+00,  3.2182e+00,  2.2568e+00,  ...,  7.2152e-01,\n",
            "            2.3957e-01, -7.9612e-01],\n",
            "          [-6.6603e-01,  2.8005e-01,  6.5047e-02,  ...,  8.3158e-01,\n",
            "           -1.3021e-01, -1.2917e+00]],\n",
            "\n",
            "         [[-1.5913e+00, -1.4795e+00, -3.6275e-01,  ...,  5.6164e-01,\n",
            "           -9.8336e-01, -5.6917e-01],\n",
            "          [-9.4212e-01,  3.1883e-01,  2.3812e-01,  ..., -9.7626e-02,\n",
            "            5.9235e-01,  1.2963e-02],\n",
            "          [-3.1008e-01, -1.4483e+00,  1.2884e+00,  ..., -1.2372e+00,\n",
            "           -1.1010e+00,  5.3827e-01],\n",
            "          ...,\n",
            "          [ 1.6705e-01, -4.9112e-02,  1.8799e+00,  ...,  1.1138e+00,\n",
            "            1.5618e+00,  1.6677e+00],\n",
            "          [ 1.2462e+00, -1.0585e-01, -8.6385e-02,  ..., -1.5751e+00,\n",
            "           -7.4602e-01, -6.5359e-01],\n",
            "          [-1.5585e+00, -2.8279e-01,  4.7291e-01,  ..., -1.4198e+00,\n",
            "            2.3437e+00, -4.9467e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1300e+00, -6.9523e-01,  1.7775e-02,  ..., -1.2878e+00,\n",
            "            3.2061e-01, -2.4966e+00],\n",
            "          [-2.3755e-01, -6.1825e-01,  2.0936e+00,  ...,  6.7684e-02,\n",
            "           -9.8288e-01, -7.1395e-02],\n",
            "          [-8.1005e-01, -6.8724e-01, -1.2925e+00,  ..., -7.3496e-01,\n",
            "           -7.6581e-01, -9.3534e-01],\n",
            "          ...,\n",
            "          [ 2.8387e-01,  5.5158e-01, -3.1667e-01,  ...,  5.5754e-01,\n",
            "           -9.4629e-02,  9.5150e-01],\n",
            "          [-5.5402e-01,  6.9626e-01, -6.2222e-01,  ..., -1.1413e+00,\n",
            "            8.5997e-01,  1.6408e+00],\n",
            "          [ 2.2683e-01, -2.3733e-01,  8.8889e-01,  ...,  2.0679e-01,\n",
            "           -8.5331e-02,  1.0734e+00]],\n",
            "\n",
            "         [[-1.0608e+00, -6.3397e-01,  7.9044e-01,  ...,  5.5294e-01,\n",
            "            1.2870e+00,  1.6220e+00],\n",
            "          [ 7.2697e-01, -8.8009e-01,  8.3756e-01,  ..., -6.7403e-01,\n",
            "           -3.3489e-01, -5.7662e-01],\n",
            "          [-4.9361e-03,  9.0921e-02, -1.6144e-01,  ...,  1.1222e+00,\n",
            "           -3.1713e-01, -7.2881e-01],\n",
            "          ...,\n",
            "          [ 3.3664e-01,  2.8155e-01,  1.1649e-01,  ..., -1.5072e+00,\n",
            "            2.5479e+00,  3.2479e-01],\n",
            "          [-4.2850e-01, -6.8506e-01,  1.3992e+00,  ..., -1.9257e+00,\n",
            "           -6.7811e-01, -2.9114e-01],\n",
            "          [-5.8381e-01,  3.6812e-01,  4.7158e-01,  ...,  8.1682e-01,\n",
            "           -4.6495e-01, -5.4063e-01]],\n",
            "\n",
            "         [[-4.7789e-02,  2.3618e-01,  1.3164e+00,  ..., -1.9839e+00,\n",
            "            8.8674e-02, -4.5994e-02],\n",
            "          [ 7.0016e-01, -7.5449e-01, -1.5155e+00,  ..., -1.0042e+00,\n",
            "            1.0167e+00,  1.7232e-01],\n",
            "          [-4.4493e-01,  1.0167e+00,  1.0029e+00,  ..., -1.0645e+00,\n",
            "           -4.0296e-01, -1.0966e+00],\n",
            "          ...,\n",
            "          [-5.1693e-01, -1.4756e+00,  6.2681e-01,  ..., -2.9087e-01,\n",
            "           -2.5870e-01,  4.6282e-01],\n",
            "          [ 2.0450e+00,  1.3579e-01, -3.4655e-01,  ..., -1.7520e-01,\n",
            "           -4.7079e-02, -2.2041e+00],\n",
            "          [-1.2651e-02, -1.1095e+00,  6.4509e-01,  ...,  9.4367e-01,\n",
            "           -9.1147e-01, -2.3045e+00]]],\n",
            "\n",
            "\n",
            "        [[[-9.4005e-01, -4.9974e-01, -9.6899e-02,  ..., -2.5534e+00,\n",
            "           -1.0261e+00,  2.6742e+00],\n",
            "          [ 1.0847e+00, -2.6822e-01,  9.1828e-01,  ..., -1.5250e-01,\n",
            "           -1.0200e+00, -1.1984e+00],\n",
            "          [ 2.1459e+00, -1.1605e+00,  9.8320e-01,  ...,  1.5476e+00,\n",
            "            1.8590e-01,  1.3698e+00],\n",
            "          ...,\n",
            "          [-1.5005e+00,  2.8272e-01,  1.4192e+00,  ...,  1.3677e+00,\n",
            "            1.1243e+00, -3.1804e-01],\n",
            "          [ 1.3781e+00, -2.1901e-01, -9.7897e-01,  ...,  4.4124e-01,\n",
            "           -4.4951e-01,  1.1574e+00],\n",
            "          [-1.2767e+00, -3.4415e-01, -2.3609e+00,  ..., -1.3242e+00,\n",
            "            5.1270e-01, -2.0223e-01]],\n",
            "\n",
            "         [[-9.9733e-01,  3.9977e-01,  1.6370e-01,  ...,  4.7625e-01,\n",
            "            1.0319e+00,  3.0938e-01],\n",
            "          [-7.6946e-01,  4.0846e-01, -6.4801e-01,  ..., -2.1120e+00,\n",
            "           -7.2424e-01,  9.9633e-01],\n",
            "          [-8.0830e-01,  6.4668e-01,  1.1789e+00,  ..., -8.0437e-01,\n",
            "           -8.2525e-01,  8.2343e-01],\n",
            "          ...,\n",
            "          [ 3.7220e-01, -1.4004e+00, -8.6571e-01,  ...,  1.5973e-01,\n",
            "           -1.5643e+00, -9.1071e-01],\n",
            "          [-4.6572e-01,  2.9555e-01, -6.4337e-01,  ..., -3.3201e-02,\n",
            "           -3.3584e-02, -2.1749e-01],\n",
            "          [ 4.3178e-02, -1.9511e-01, -5.5384e-01,  ..., -2.4733e-01,\n",
            "            1.1478e+00, -7.6722e-01]],\n",
            "\n",
            "         [[-2.2897e+00,  8.0021e-01, -4.2427e-01,  ...,  7.7525e-02,\n",
            "            3.3563e-01,  7.3734e-01],\n",
            "          [-1.5693e+00,  1.3821e+00,  1.4347e+00,  ...,  7.4515e-01,\n",
            "           -2.9778e-01,  6.6887e-01],\n",
            "          [ 1.4101e+00, -7.3060e-01, -2.2573e-01,  ..., -7.2327e-01,\n",
            "           -3.7199e-01,  8.1583e-01],\n",
            "          ...,\n",
            "          [ 9.0084e-02, -1.3763e+00,  9.0261e-01,  ...,  1.7340e+00,\n",
            "            1.1169e+00, -1.4838e+00],\n",
            "          [-4.0810e-01, -2.6661e-01,  1.6662e+00,  ..., -9.4730e-02,\n",
            "            1.1105e+00, -6.6881e-02],\n",
            "          [-7.9374e-01,  1.2587e-01, -6.3672e-02,  ..., -1.4476e+00,\n",
            "            2.4229e-01, -1.1366e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1435e+00,  1.4759e-01, -3.5175e-01,  ..., -2.2018e+00,\n",
            "           -5.4331e-01,  5.9242e-02],\n",
            "          [ 8.0379e-01, -1.4375e+00,  1.1359e+00,  ..., -1.1613e+00,\n",
            "            5.0937e-01,  1.7510e+00],\n",
            "          [ 3.3824e-01,  1.3973e-01, -5.1132e-01,  ...,  1.8106e+00,\n",
            "            5.4883e-01,  1.0580e+00],\n",
            "          ...,\n",
            "          [-1.2528e+00, -9.5282e-01,  2.9858e-01,  ...,  9.5604e-01,\n",
            "           -2.0626e-01, -4.6171e-01],\n",
            "          [ 2.9658e-01,  6.8445e-01,  2.5468e-01,  ...,  1.0472e+00,\n",
            "           -1.3597e+00, -4.0211e-01],\n",
            "          [-1.3848e-01,  3.5785e-01,  2.3235e-01,  ...,  2.9594e-01,\n",
            "           -1.0419e+00,  1.7023e+00]],\n",
            "\n",
            "         [[ 4.3139e-01,  1.5660e-01, -5.9841e-01,  ..., -2.5736e+00,\n",
            "            1.3238e-01,  2.7096e-02],\n",
            "          [ 9.4649e-01,  2.4397e-01,  9.6799e-02,  ..., -4.7586e-01,\n",
            "            1.2933e+00,  4.7520e-01],\n",
            "          [ 5.5404e-01,  9.0546e-01, -6.2337e-01,  ..., -1.0907e+00,\n",
            "            7.5340e-01,  1.2690e+00],\n",
            "          ...,\n",
            "          [-1.5680e+00,  1.7957e+00, -3.2464e-01,  ...,  1.4043e+00,\n",
            "            5.5160e-01,  5.2944e-01],\n",
            "          [-2.0765e-01,  9.3832e-02,  8.5663e-01,  ...,  5.1244e-01,\n",
            "           -8.0189e-01,  1.2362e+00],\n",
            "          [ 2.4164e-01,  3.6926e-01,  1.6047e+00,  ...,  8.2063e-01,\n",
            "           -2.8473e-01, -1.0212e+00]],\n",
            "\n",
            "         [[-4.0301e-02, -8.3192e-01,  6.2976e-01,  ..., -1.5782e+00,\n",
            "            6.4091e-01,  5.7037e-01],\n",
            "          [-1.7213e-01,  3.2682e-01, -2.3523e-01,  ...,  6.5134e-01,\n",
            "            9.4765e-01, -9.3565e-01],\n",
            "          [ 1.4552e-01, -1.1095e+00,  5.8714e-01,  ...,  2.5279e-01,\n",
            "            3.6599e-01,  1.2642e+00],\n",
            "          ...,\n",
            "          [ 1.7131e+00,  7.2474e-01,  7.1587e-02,  ..., -5.3130e-01,\n",
            "           -6.0263e-01, -7.3002e-01],\n",
            "          [-2.5427e-02,  2.1895e-01,  1.2070e+00,  ...,  1.5683e+00,\n",
            "           -5.4082e-01, -2.7154e-01],\n",
            "          [-5.5023e-02, -1.1931e-01, -2.8384e-01,  ...,  1.5123e+00,\n",
            "            4.1118e-01,  1.7663e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 9.0462e-01, -1.1902e-01, -4.7497e-01,  ..., -2.1082e-01,\n",
            "            9.6242e-01, -3.1653e-01],\n",
            "          [-5.2894e-01, -6.8115e-01, -1.1938e+00,  ...,  3.1190e-01,\n",
            "           -4.4836e-01, -2.1431e-02],\n",
            "          [-6.5300e-02,  2.2716e+00,  3.7653e-01,  ...,  4.3600e-01,\n",
            "            7.8991e-01, -1.9885e+00],\n",
            "          ...,\n",
            "          [ 1.7649e+00, -3.2315e-01,  1.1018e+00,  ..., -1.1660e+00,\n",
            "           -2.1219e-01,  7.9424e-01],\n",
            "          [-1.0289e+00, -8.5288e-01, -8.6248e-04,  ..., -7.1905e-01,\n",
            "           -4.8638e-01, -6.6776e-02],\n",
            "          [ 1.1357e+00, -1.5070e+00, -1.8360e-01,  ...,  4.4764e-01,\n",
            "           -7.3721e-01, -1.2588e+00]],\n",
            "\n",
            "         [[ 5.5193e-01, -4.8904e-01,  2.3917e-01,  ...,  1.3986e+00,\n",
            "            1.5265e-01, -1.7563e+00],\n",
            "          [ 8.1229e-01,  1.3225e+00,  1.9252e-01,  ..., -3.9545e-01,\n",
            "            4.1192e-02,  3.1512e+00],\n",
            "          [ 1.0151e+00, -1.0435e+00, -1.3966e+00,  ..., -8.1082e-01,\n",
            "           -5.2940e-01, -2.6621e-01],\n",
            "          ...,\n",
            "          [ 1.5705e+00, -1.3677e+00,  1.5126e-01,  ..., -9.6350e-01,\n",
            "           -8.3539e-01,  9.3891e-02],\n",
            "          [ 9.6814e-01,  6.0544e-01, -1.7272e-01,  ...,  8.3167e-01,\n",
            "           -1.5665e+00, -1.4005e+00],\n",
            "          [ 1.0231e+00,  7.5360e-01,  5.2981e-02,  ...,  5.0153e-01,\n",
            "           -1.2106e+00,  8.5676e-01]],\n",
            "\n",
            "         [[ 1.9691e+00, -2.3853e-01, -9.2440e-01,  ...,  8.9587e-01,\n",
            "           -5.6017e-02, -5.4041e-01],\n",
            "          [ 4.8576e-01, -9.8379e-01,  1.4978e+00,  ...,  1.9908e+00,\n",
            "            8.6990e-01, -1.5294e-01],\n",
            "          [ 1.8492e-02,  3.1632e-01,  2.1401e-01,  ...,  1.5516e+00,\n",
            "            3.1395e-02, -8.6982e-01],\n",
            "          ...,\n",
            "          [ 5.5657e-01, -1.8259e+00, -6.2022e-01,  ...,  8.2837e-02,\n",
            "            1.4598e-01,  6.6070e-01],\n",
            "          [-1.9278e+00,  5.4630e-01,  1.2757e+00,  ..., -1.2858e+00,\n",
            "           -4.2094e-01,  1.0849e+00],\n",
            "          [ 1.9797e+00, -7.4616e-01, -1.4287e+00,  ...,  1.5372e+00,\n",
            "            3.9460e-01,  1.4918e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3376e+00,  1.7416e+00, -2.2179e+00,  ..., -1.2724e+00,\n",
            "           -1.2422e+00, -1.6970e+00],\n",
            "          [ 3.7431e-01, -3.7700e-01,  2.2186e+00,  ..., -2.3448e-01,\n",
            "           -4.3032e-01,  2.5555e+00],\n",
            "          [-5.2620e-01,  2.5789e-02,  1.1484e+00,  ...,  9.5188e-01,\n",
            "            6.2880e-01, -1.6498e+00],\n",
            "          ...,\n",
            "          [ 7.7735e-01,  1.0131e-01, -7.0709e-01,  ..., -2.9838e-01,\n",
            "           -7.1542e-01,  1.2357e+00],\n",
            "          [-2.0389e-01,  1.0009e+00, -8.3850e-02,  ...,  1.0161e-01,\n",
            "            9.5488e-01, -2.1945e+00],\n",
            "          [ 3.0243e-01, -2.2111e+00, -1.0716e+00,  ..., -2.3540e+00,\n",
            "           -1.0264e+00, -8.1657e-01]],\n",
            "\n",
            "         [[ 1.3763e-01,  9.4004e-01,  2.3876e-01,  ...,  1.0203e+00,\n",
            "           -1.7733e+00,  1.1783e+00],\n",
            "          [-2.7606e-02, -7.4153e-01,  9.8623e-01,  ..., -1.5900e+00,\n",
            "           -3.2665e-01,  4.1902e-01],\n",
            "          [-7.5829e-01,  4.7905e-01, -5.8033e-01,  ...,  2.9614e-01,\n",
            "            9.6999e-02,  5.2409e-01],\n",
            "          ...,\n",
            "          [ 3.0156e-01,  1.0392e+00,  7.6579e-01,  ...,  6.1602e-01,\n",
            "           -8.1765e-01,  5.8157e-01],\n",
            "          [-1.5356e+00,  9.4671e-01,  3.7048e-01,  ...,  7.2236e-01,\n",
            "           -3.9739e-01, -9.0046e-01],\n",
            "          [-1.5901e-01,  1.7489e+00, -1.2027e-01,  ...,  3.2698e-01,\n",
            "           -1.3195e-01, -1.4956e+00]],\n",
            "\n",
            "         [[ 1.4715e-01,  2.6039e-01,  5.2210e-01,  ..., -9.8573e-01,\n",
            "            2.5332e-01, -1.0035e+00],\n",
            "          [-1.7843e+00,  1.2175e+00,  5.5262e-01,  ..., -2.5759e-01,\n",
            "           -3.2513e-01, -6.7315e-01],\n",
            "          [ 1.6309e-01, -7.1845e-01,  8.9626e-01,  ...,  1.4889e+00,\n",
            "            1.1212e+00,  5.6966e-02],\n",
            "          ...,\n",
            "          [ 3.7463e-01,  1.1501e-01,  5.1538e-01,  ...,  7.7417e-02,\n",
            "            1.0264e+00,  9.7965e-02],\n",
            "          [-1.6051e+00,  8.3099e-01,  6.1490e-01,  ..., -1.0824e+00,\n",
            "            2.3775e+00,  7.8828e-01],\n",
            "          [ 5.6715e-02, -9.1985e-01, -1.2787e-01,  ..., -2.1491e+00,\n",
            "           -4.0314e-01,  1.6380e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.4647e+00,  1.9814e+00,  2.4726e+00,  ..., -9.7718e-01,\n",
            "           -7.9332e-01, -1.4952e+00],\n",
            "          [-7.8226e-01, -1.2199e+00, -4.2487e-02,  ...,  1.6967e+00,\n",
            "           -7.2934e-01, -5.7265e-01],\n",
            "          [ 3.8242e-01,  2.1273e-01, -7.0721e-01,  ..., -1.0914e+00,\n",
            "            1.3883e+00, -1.1953e+00],\n",
            "          ...,\n",
            "          [-1.0758e+00,  7.0216e-01,  1.0557e+00,  ..., -1.5782e+00,\n",
            "            1.7956e+00,  3.0656e-01],\n",
            "          [-3.9239e-01,  1.1054e+00, -1.1403e+00,  ...,  2.2994e-01,\n",
            "            1.2574e+00, -7.6585e-01],\n",
            "          [ 2.5561e+00, -6.3573e-02, -1.1318e+00,  ..., -1.2895e+00,\n",
            "            1.9808e-01,  1.0907e+00]],\n",
            "\n",
            "         [[ 1.4436e+00, -1.1919e+00, -7.9525e-01,  ..., -1.3069e-01,\n",
            "           -1.3412e+00, -2.8781e-01],\n",
            "          [ 8.8433e-01, -1.8080e+00, -9.6914e-01,  ..., -7.9541e-01,\n",
            "            2.9306e-01,  3.1384e-01],\n",
            "          [-6.9608e-01,  1.2940e+00, -3.7702e-02,  ...,  1.6838e+00,\n",
            "           -1.6566e+00, -6.7490e-01],\n",
            "          ...,\n",
            "          [ 6.8818e-02,  1.0350e+00,  2.0238e+00,  ...,  1.5995e+00,\n",
            "           -3.8418e-01, -1.7478e+00],\n",
            "          [-6.3672e-01,  1.6808e+00, -1.7499e+00,  ...,  2.6068e-01,\n",
            "           -6.0163e-01, -1.1609e+00],\n",
            "          [-1.6252e+00,  1.3428e+00, -6.0415e-01,  ..., -1.0586e+00,\n",
            "            8.0017e-01,  7.0265e-01]],\n",
            "\n",
            "         [[-2.0224e-01, -4.9635e-01, -4.9353e-01,  ...,  7.1474e-01,\n",
            "           -3.2963e-01, -5.6337e-01],\n",
            "          [-6.7342e-01, -1.3102e+00,  4.3232e-01,  ..., -2.3034e-01,\n",
            "           -3.0701e-01,  5.2608e-01],\n",
            "          [-9.3304e-01,  1.5988e+00,  1.4633e+00,  ..., -4.5957e-01,\n",
            "           -9.8018e-01,  5.5519e-01],\n",
            "          ...,\n",
            "          [ 6.2697e-01,  2.2390e+00,  5.4888e-01,  ...,  4.8741e-02,\n",
            "           -1.2522e-01,  9.9320e-01],\n",
            "          [-1.5575e+00,  3.0727e-01,  4.6000e-01,  ...,  3.0565e-02,\n",
            "            1.6411e-01, -1.9610e+00],\n",
            "          [ 2.6288e-01,  2.4823e-01, -8.6408e-01,  ...,  1.5068e+00,\n",
            "            1.1897e+00,  6.9866e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2994e+00,  1.1938e-01, -1.7706e+00,  ..., -1.2504e+00,\n",
            "            5.0493e-01, -1.0511e+00],\n",
            "          [-8.4841e-01, -2.3163e-01, -1.1569e+00,  ...,  9.9010e-01,\n",
            "            7.1283e-01, -1.5772e-01],\n",
            "          [ 1.6934e-01,  8.2230e-01, -7.7093e-01,  ..., -1.8357e+00,\n",
            "            8.9830e-02, -7.8425e-01],\n",
            "          ...,\n",
            "          [ 1.4935e+00,  4.4935e-01, -1.2973e+00,  ...,  4.6440e-01,\n",
            "            2.5790e-01, -2.3648e-01],\n",
            "          [ 8.1039e-01, -9.1533e-01,  5.7923e-01,  ..., -1.2370e+00,\n",
            "            8.7891e-01,  1.2084e-01],\n",
            "          [ 4.9222e-01, -1.1513e-01, -1.5032e+00,  ...,  1.5935e+00,\n",
            "           -1.1343e-01, -6.7308e-02]],\n",
            "\n",
            "         [[ 1.4523e+00, -1.0715e+00, -7.9336e-01,  ...,  1.9580e+00,\n",
            "           -1.6586e+00,  2.3546e+00],\n",
            "          [ 1.9324e+00, -4.2787e-01, -4.1203e-01,  ..., -3.4207e-01,\n",
            "           -7.7807e-01,  5.3158e-01],\n",
            "          [-1.5393e+00,  1.5014e+00, -4.4165e-01,  ...,  4.2698e-01,\n",
            "           -5.4725e-01,  8.5018e-02],\n",
            "          ...,\n",
            "          [-8.3138e-02, -4.4567e-01, -3.9842e-03,  ...,  1.3420e+00,\n",
            "            4.3388e-01, -6.8089e-01],\n",
            "          [ 2.3103e+00, -2.7259e-01,  1.5995e+00,  ...,  1.2767e+00,\n",
            "            2.0362e-01, -3.9786e-01],\n",
            "          [ 2.2705e-01, -6.3010e-01,  7.6075e-01,  ...,  1.4468e-01,\n",
            "           -9.5723e-01,  6.9669e-01]],\n",
            "\n",
            "         [[ 4.7998e-01,  6.4639e-01, -8.7868e-01,  ..., -1.2768e+00,\n",
            "            4.6027e-02,  3.2371e-01],\n",
            "          [-4.6317e-01,  7.9987e-01, -4.0083e-01,  ...,  4.9943e-02,\n",
            "            6.8320e-01, -7.4923e-01],\n",
            "          [ 1.4042e+00, -4.6323e-01, -3.2061e-01,  ...,  5.4931e-02,\n",
            "            4.6379e-02, -7.7225e-01],\n",
            "          ...,\n",
            "          [-3.2037e-01, -6.2040e-01, -6.3166e-01,  ..., -2.0135e-01,\n",
            "            1.1804e+00,  6.3322e-02],\n",
            "          [-2.9815e+00, -6.0158e-01,  2.0875e-01,  ..., -5.3711e-01,\n",
            "            1.6179e+00, -4.2109e-01],\n",
            "          [-1.2298e+00,  4.2504e-01,  4.8645e-01,  ...,  3.2923e-01,\n",
            "           -1.0082e+00, -8.7464e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4125e+00,  1.2532e+00,  4.6408e-01,  ..., -1.4241e+00,\n",
            "            1.5273e+00, -8.6399e-01],\n",
            "          [ 4.0235e-01,  9.1577e-01, -6.7223e-01,  ...,  7.1501e-01,\n",
            "            9.6399e-01,  1.1313e-02],\n",
            "          [ 8.8625e-01, -2.6509e-01,  1.3976e+00,  ...,  4.8659e-01,\n",
            "           -8.0219e-01, -2.8648e+00],\n",
            "          ...,\n",
            "          [-9.8588e-01,  4.6750e-01, -2.5230e+00,  ..., -7.0218e-01,\n",
            "           -2.5427e+00, -7.0450e-01],\n",
            "          [ 3.0728e-01, -3.7782e-01, -8.9977e-01,  ...,  2.0485e+00,\n",
            "           -1.7741e+00,  7.7187e-01],\n",
            "          [ 5.3150e-01,  8.8600e-03,  3.4226e-01,  ...,  1.0374e+00,\n",
            "            1.2882e-01, -5.6462e-01]],\n",
            "\n",
            "         [[-1.6849e+00,  1.9997e+00, -3.2047e-01,  ...,  7.9805e-02,\n",
            "            1.8748e+00,  7.7383e-01],\n",
            "          [ 1.8354e-01,  1.2930e+00,  6.2795e-01,  ...,  4.1521e-01,\n",
            "            1.0265e+00,  1.9216e-01],\n",
            "          [-6.8079e-03, -1.0491e+00,  1.8393e+00,  ..., -1.3929e-01,\n",
            "           -7.0424e-01,  1.1601e+00],\n",
            "          ...,\n",
            "          [ 5.4684e-01,  5.6516e-01,  2.7493e+00,  ..., -5.6972e-02,\n",
            "           -9.4361e-01, -1.4456e+00],\n",
            "          [ 5.5971e-01, -2.3808e-01, -1.3371e+00,  ..., -4.9450e-02,\n",
            "           -4.6887e-01, -2.0938e+00],\n",
            "          [ 3.7442e-01,  1.8945e-01, -1.3840e-01,  ...,  6.1357e-01,\n",
            "           -1.2949e-01,  1.1180e+00]],\n",
            "\n",
            "         [[-6.5681e-02,  6.3614e-01, -9.9658e-01,  ..., -2.1842e+00,\n",
            "            7.9206e-01,  2.2306e-02],\n",
            "          [ 1.4513e+00,  6.3083e-01,  1.1803e+00,  ..., -1.4914e+00,\n",
            "            1.0930e+00, -1.4963e+00],\n",
            "          [ 1.0466e+00, -4.3624e-01, -9.9926e-01,  ...,  1.2419e+00,\n",
            "           -8.4127e-01,  5.4384e-02],\n",
            "          ...,\n",
            "          [-4.5005e-01, -9.2663e-01, -2.4357e-01,  ...,  1.6674e+00,\n",
            "            4.6462e-01,  1.0380e+00],\n",
            "          [ 4.4560e-01,  6.4029e-01,  7.8011e-01,  ..., -7.0348e-01,\n",
            "           -4.0270e-02, -1.0332e+00],\n",
            "          [ 1.1579e-01, -3.2000e-01, -3.4399e-02,  ..., -7.0362e-02,\n",
            "            2.2502e+00, -6.4704e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3332e+00, -1.3743e+00,  1.2297e+00,  ...,  1.8174e-01,\n",
            "            9.8023e-01, -9.3548e-01],\n",
            "          [ 5.7758e-01,  1.5005e-01, -1.0987e+00,  ..., -6.4080e-01,\n",
            "            2.7364e-01,  1.2984e+00],\n",
            "          [-4.4844e-01, -2.4765e-01,  5.0524e-01,  ..., -1.1353e-01,\n",
            "            2.2396e+00,  4.6394e-01],\n",
            "          ...,\n",
            "          [-7.7985e-01, -6.8718e-01,  1.8709e+00,  ..., -7.5645e-01,\n",
            "           -1.0621e+00,  7.5367e-01],\n",
            "          [ 4.0522e-01, -4.6515e-01, -3.3234e-01,  ..., -8.0672e-01,\n",
            "            7.2203e-01, -3.0079e-01],\n",
            "          [ 7.7284e-01, -4.7659e-01, -1.5807e+00,  ...,  9.6978e-01,\n",
            "           -3.0056e-01, -1.2305e+00]],\n",
            "\n",
            "         [[ 7.5639e-01, -9.7905e-01,  1.1527e+00,  ..., -4.2049e-01,\n",
            "            7.6043e-01,  1.9003e-01],\n",
            "          [ 1.7921e-02, -1.7330e+00,  8.3184e-01,  ...,  9.5650e-01,\n",
            "           -5.1579e-01, -3.4475e-01],\n",
            "          [ 8.7037e-02,  6.3010e-01, -5.5232e-01,  ..., -2.1664e-01,\n",
            "           -5.8223e-01,  1.3727e+00],\n",
            "          ...,\n",
            "          [-1.6781e+00,  2.0596e+00, -1.5593e+00,  ...,  6.4454e-01,\n",
            "            8.8308e-01,  7.6573e-01],\n",
            "          [-9.6371e-01, -6.4461e-01, -5.2819e-01,  ...,  4.4948e-01,\n",
            "            1.3968e+00,  1.3895e-01],\n",
            "          [ 6.3861e-01, -1.6137e+00, -1.5846e+00,  ...,  4.1523e-01,\n",
            "           -2.5555e-02,  6.7022e-01]],\n",
            "\n",
            "         [[-1.3874e+00,  9.2363e-01,  2.1473e-01,  ..., -2.5575e-01,\n",
            "           -1.4539e+00, -5.3276e-01],\n",
            "          [-1.8901e-01, -1.0018e-01,  6.4638e-01,  ..., -8.4670e-01,\n",
            "           -7.6473e-01,  4.5058e-01],\n",
            "          [ 1.4980e-01,  1.4341e+00, -1.1508e+00,  ..., -3.1694e-01,\n",
            "            1.0008e+00,  1.6067e+00],\n",
            "          ...,\n",
            "          [-2.4227e+00, -7.3469e-01,  2.8262e-01,  ..., -6.6673e-01,\n",
            "            7.0905e-01, -1.3570e-01],\n",
            "          [-1.2152e+00, -1.4592e+00,  5.7388e-01,  ..., -6.4802e-01,\n",
            "            2.0337e-01, -6.9089e-01],\n",
            "          [ 2.4750e-01,  1.0183e+00,  1.7735e-01,  ..., -9.2119e-01,\n",
            "            8.0080e-01,  5.5304e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.0121e-02, -2.0489e-02,  1.3513e+00,  ..., -5.4801e-01,\n",
            "            1.6672e+00, -2.2566e+00],\n",
            "          [ 3.0064e-01, -1.2730e+00, -9.6219e-01,  ...,  4.0964e-01,\n",
            "            2.9403e-01, -2.1938e+00],\n",
            "          [-1.6084e+00,  9.5145e-01,  5.6279e-01,  ..., -1.4809e-01,\n",
            "           -1.5521e+00, -2.8199e-02],\n",
            "          ...,\n",
            "          [-1.7595e+00,  1.2924e+00, -2.2833e+00,  ..., -1.1548e+00,\n",
            "            5.6004e-01,  1.0131e+00],\n",
            "          [-6.4235e-01,  3.0881e-01,  9.8540e-02,  ...,  1.0187e+00,\n",
            "            2.4221e+00, -5.0145e-01],\n",
            "          [ 8.6502e-01, -1.7534e+00,  3.5200e-01,  ..., -4.7648e-01,\n",
            "            1.5277e+00,  6.3155e-01]],\n",
            "\n",
            "         [[-1.0546e+00,  2.3788e-01,  1.9482e+00,  ...,  1.0235e+00,\n",
            "            1.3538e+00,  1.8676e-01],\n",
            "          [-1.0533e+00,  7.1408e-01,  5.4680e-01,  ..., -1.3760e+00,\n",
            "            9.4430e-01,  2.1908e+00],\n",
            "          [ 1.5616e+00, -6.2173e-01,  1.0924e-01,  ..., -1.6862e+00,\n",
            "            1.4074e+00,  3.3783e-01],\n",
            "          ...,\n",
            "          [-3.2201e-01, -4.7325e-01,  1.5195e+00,  ...,  6.1620e-01,\n",
            "            1.6274e-01,  2.0250e+00],\n",
            "          [ 3.1998e-01,  2.6789e-01,  6.2258e-01,  ...,  3.4497e-01,\n",
            "           -2.1030e-02,  1.2494e-01],\n",
            "          [ 3.7387e-02,  1.3466e+00,  1.3986e-01,  ...,  1.1772e+00,\n",
            "            7.8788e-01,  1.7920e+00]],\n",
            "\n",
            "         [[ 1.8740e-01,  1.4667e+00,  1.6280e-01,  ...,  2.2082e+00,\n",
            "           -3.9452e-01,  9.2945e-02],\n",
            "          [ 3.9022e-01,  1.9306e+00, -1.3118e-01,  ..., -5.5065e-01,\n",
            "           -1.1900e+00, -5.6896e-01],\n",
            "          [ 1.9136e+00, -1.7672e-01, -1.0842e+00,  ...,  1.5566e+00,\n",
            "            1.4406e+00,  1.0385e-01],\n",
            "          ...,\n",
            "          [-9.6652e-01, -4.4646e-01, -4.0888e-01,  ...,  8.3639e-01,\n",
            "            5.9657e-01, -9.7824e-01],\n",
            "          [-2.3981e-01, -8.5001e-01,  1.5487e-01,  ...,  1.2570e+00,\n",
            "           -3.0994e-01, -2.1188e+00],\n",
            "          [-1.0120e+00, -1.4912e+00,  1.7550e-01,  ..., -6.4965e-03,\n",
            "            8.2457e-02, -9.6147e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4267e+00, -4.4554e-01, -1.7657e-01,  ...,  2.2523e+00,\n",
            "           -1.2359e+00,  2.4383e-01],\n",
            "          [-5.2465e-01,  7.5969e-01, -2.0785e-01,  ..., -2.2349e-01,\n",
            "           -3.0205e-02, -5.7387e-01],\n",
            "          [-2.6442e-01, -8.3526e-01, -1.2372e+00,  ..., -4.5487e-01,\n",
            "            9.2826e-01,  2.9460e-01],\n",
            "          ...,\n",
            "          [ 5.0593e-02,  6.4222e-01, -1.0015e+00,  ..., -2.7305e-01,\n",
            "           -9.1834e-01, -6.8120e-01],\n",
            "          [-6.6407e-01, -1.8470e-01, -7.9106e-01,  ...,  5.0908e-02,\n",
            "            1.1848e+00, -5.8453e-02],\n",
            "          [ 1.9176e+00,  1.1949e+00, -1.3074e+00,  ...,  1.1587e+00,\n",
            "            5.4069e-01, -1.6431e+00]],\n",
            "\n",
            "         [[-2.3715e-01, -1.1222e+00,  3.2903e-01,  ...,  4.0472e-01,\n",
            "           -1.4496e+00,  2.1672e-01],\n",
            "          [-1.0690e+00,  1.8175e+00,  1.0581e+00,  ...,  7.1055e-01,\n",
            "           -6.6611e-02,  4.6069e-01],\n",
            "          [ 3.9917e-01, -1.1136e-01,  4.9591e-01,  ...,  1.8456e+00,\n",
            "            2.7919e-01, -1.9432e+00],\n",
            "          ...,\n",
            "          [-1.1653e+00,  2.3223e+00, -7.6952e-02,  ..., -1.3543e+00,\n",
            "           -6.9370e-01, -2.0935e+00],\n",
            "          [ 6.9910e-01, -3.2686e-01, -1.8641e+00,  ...,  1.6394e+00,\n",
            "           -2.4826e-01, -5.6655e-01],\n",
            "          [-6.1204e-01,  1.4917e+00,  8.7036e-01,  ..., -2.5769e+00,\n",
            "            1.6929e+00,  1.2563e+00]],\n",
            "\n",
            "         [[-3.9162e-01, -1.8765e+00,  1.0266e+00,  ..., -7.4552e-01,\n",
            "            7.8360e-01, -1.6420e+00],\n",
            "          [-4.6161e-01, -5.2292e-01,  3.2999e-01,  ...,  1.0041e+00,\n",
            "           -1.5286e-01, -1.1389e+00],\n",
            "          [ 4.0810e-02, -4.6203e-01, -7.6707e-01,  ..., -4.8261e-01,\n",
            "            1.2526e+00,  3.1933e-01],\n",
            "          ...,\n",
            "          [-2.3534e-01, -1.7831e+00,  3.4076e-01,  ...,  3.0446e-01,\n",
            "            2.4249e-01, -5.8986e-01],\n",
            "          [-1.5188e-01,  1.6027e+00, -1.8920e+00,  ..., -1.3166e+00,\n",
            "            1.3994e+00, -6.1046e-01],\n",
            "          [ 1.3691e+00,  3.6258e-02, -9.7683e-02,  ..., -1.2340e+00,\n",
            "            2.4715e-01, -2.6326e+00]]]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-41ea11f76f01>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0minception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionNaive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1x1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc3x3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch5x5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: InceptionNaive.__init__() got an unexpected keyword argument 'c1x1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3,3 kernel\n",
        "ch3x3red, ch3x3 = 96, 128\n",
        "\n",
        "branch2 = nn.Sequential(\n",
        "    ConvBlock(in_channels=192, out_channels=ch3x3red, kernel_size=1),\n",
        "    ConvBlock(in_channels=ch3x3red, out_channels=ch3x3, kernel_size=3)\n",
        ")\n",
        "out_branch2 = branch2(input_tensor)\n",
        "print(\"Branch2: \", out_branch2.shape)\n",
        "\n",
        "\n",
        "#5,5 kernel\n",
        "ch5x5red, ch5x5 = 16, 32\n",
        "\n",
        "branch2 = nn.Sequential(\n",
        "    ConvBlock(in_channels=16, out_channels=ch5x5red, kernel_size=1),\n",
        "    ConvBlock(in_channels=ch5x5red, out_channels=ch5x5, kernel_size=5, padding = 2)\n",
        ")\n",
        "out_branch2 = branch2(input_tensor)\n",
        "print(\"Branch2: \", out_branch2.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "V2vmh_68IRhc",
        "outputId": "33bec055-8aa1-4117-9a99-ad50bd33e043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch2:  torch.Size([32, 128, 98, 98])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-56302b859ac2>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch5x5red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch5x5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mout_branch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbranch2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Branch2: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_branch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f4a5a205e334>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 16, 1, 1], expected input[32, 192, 100, 100] to have 16 channels, but got 192 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "C,H,W  = 192, 100, 100\n",
        "\n",
        "\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "  def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj=0):\n",
        "    super(InceptionModule, self).__init__()\n",
        "\n",
        "    self.branch1 = ConvBlock(in_channels=in_channels, out_channels=ch1x1, kernel_size=1, padding=0, stride=1)\n",
        "\n",
        "    self.branch2 = nn.Sequential(\n",
        "    ConvBlock(in_channels=in_channels, out_channels=ch3x3red, kernel_size=1),\n",
        "    ConvBlock(in_channels=ch3x3red, out_channels=ch3x3, kernel_size=3, padding = 1))\n",
        "\n",
        "    self.branch3 = nn.Sequential(\n",
        "    ConvBlock(in_channels=in_channels, out_channels=ch5x5red, kernel_size=1),\n",
        "    ConvBlock(in_channels=ch5x5red, out_channels=ch5x5, kernel_size=5, padding = 2))\n",
        "\n",
        "    self.branch4 = nn.Sequential(\n",
        "    nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
        "    ConvBlock(in_channels=in_channels, out_channels=pool_proj, kernel_size=1)\n",
        ")\n",
        "\n",
        "  def forward(self, x):\n",
        "    out_branch1 = self.branch1(x)\n",
        "    out_branch2 = self.branch2(x)\n",
        "    out_branch3 = self.branch3(x)\n",
        "    out_branch4 = self.branch4(x)\n",
        "\n",
        "    x = torch.concat([out_branch1, out_branch2, out_branch3, out_branch4],axis=1)\n",
        "    return x\n",
        "\n",
        "\n",
        "# BATCH_SIZE = 32\n",
        "# H, W = 100, 100\n",
        "# channels = 192\n",
        "# pool_proj = 32\n",
        "\n",
        "# input_tensor = torch.randn(size=(BATCH_SIZE, channels, H, W))\n",
        "# print(\"Input: \", input_tensor)\n",
        "\n",
        "# inception = InceptionModule(in_channels=192, ch1x1=64, ch3x3red=96, ch3x3=128, ch5x5red=16, ch5x5=32, pool_proj=32)\n",
        "# output_tensor = inception(input_tensor)\n",
        "# print(\"Output: \", output_tensor)"
      ],
      "metadata": {
        "id": "4L-1yLU9do6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6jA9Nkqd-weH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GoogLeNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "    self.conv1_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1, stride=1)\n",
        "    self.conv2_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.inception3a = InceptionModule(in_channels=192, ch1x1=64, ch3x3red=96, ch3x3=128, ch5x5red=16, ch5x5=32, pool_proj=32)\n",
        "    self.inception3b = InceptionModule(in_channels=256, ch1x1=128, ch3x3red=128, ch3x3=192, ch5x5red=32, ch5x5=96, pool_proj=64)\n",
        "    self.inception3_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.inception4a = InceptionModule(in_channels=480, ch1x1=192, ch3x3red=96, ch3x3=208, ch5x5red=16, ch5x5=48, pool_proj=64)\n",
        "    self.inception4b = InceptionModule(in_channels=512, ch1x1=160, ch3x3red=112, ch3x3=224, ch5x5red=24, ch5x5=64, pool_proj=64)\n",
        "    self.inception4c = InceptionModule(in_channels=512, ch1x1=128, ch3x3red=128, ch3x3=256, ch5x5red=24, ch5x5=64, pool_proj=64)\n",
        "    self.inception4d = InceptionModule(in_channels=512, ch1x1=112, ch3x3red=144, ch3x3=288, ch5x5red=32, ch5x5=64, pool_proj=64)\n",
        "    self.inception4e = InceptionModule(in_channels=528, ch1x1=256, ch3x3red=160, ch3x3=320, ch5x5red=32, ch5x5=128, pool_proj=128)\n",
        "    self.inception4_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.inception5a = InceptionModule(in_channels=832, ch1x1=256, ch3x3red=160, ch3x3=320, ch5x5red=32, ch5x5=128, pool_proj=128)\n",
        "    self.inception5b = InceptionModule(in_channels=832, ch1x1=384, ch3x3red=192, ch3x3=384, ch5x5red=48, ch5x5=128, pool_proj=128)\n",
        "    self.inception5_pool = nn.AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=1024 , out_features=1000)\n",
        "    self.fc2 = nn.Linear(in_features=1000 , out_features=1000)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    print(f\"conv1: {x.shape}\")\n",
        "    x = self.conv1_pool(x)\n",
        "    print(f\"conv1_pool: {x.shape}\")\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    print(f\"conv2: {x.shape}\")\n",
        "    x = self.conv2_pool(x)\n",
        "    print(f\"conv2_pool: {x.shape}\")\n",
        "\n",
        "    x = self.inception3a(x)\n",
        "    print(f\"inception3a: {x.shape}\")\n",
        "    x = self.inception3b(x)\n",
        "    print(f\"inception3b: {x.shape}\")\n",
        "    x = self.inception3_pool(x)\n",
        "\n",
        "    x = self.inception4a(x)\n",
        "    print(f\"inception4a: {x.shape}\")\n",
        "    x = self.inception4b(x)\n",
        "    print(f\"inception4b: {x.shape}\")\n",
        "    x = self.inception4c(x)\n",
        "    print(f\"inception4c: {x.shape}\")\n",
        "    x = self.inception4d(x)\n",
        "    print(f\"inception4d: {x.shape}\")\n",
        "    x = self.inception4e(x)\n",
        "    print(f\"inception4e: {x.shape}\")\n",
        "    x = self.inception4_pool(x)\n",
        "    print(f\"inception4_pool: {x.shape}\")\n",
        "\n",
        "    x = self.inception5a(x)\n",
        "    print(f\"inception5a: {x.shape}\")\n",
        "    x = self.inception5b(x)\n",
        "    print(f\"inception5b: {x.shape}\")\n",
        "    x = self.inception5_pool(x)\n",
        "    print(f\"inception5_pool: {x.shape}\")\n",
        "\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = self.fc1(x)\n",
        "    print(f\"fc1: {x.shape}\")\n",
        "    x = self.fc2(x)\n",
        "    print(f\"fc2: {x.shape}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "H, W = 224, 224\n",
        "channels = 3\n",
        "\n",
        "input_tensor = torch.randn(size=(BATCH_SIZE, channels, H, W))\n",
        "\n",
        "model = GoogLeNet()\n",
        "model(input_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hmvXAjLmLZz",
        "outputId": "270bb902-dd81-4423-ddf7-8001c5a4c33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1: torch.Size([32, 64, 112, 112])\n",
            "conv1_pool: torch.Size([32, 64, 56, 56])\n",
            "conv2: torch.Size([32, 192, 56, 56])\n",
            "conv2_pool: torch.Size([32, 192, 28, 28])\n",
            "inception3a: torch.Size([32, 256, 28, 28])\n",
            "inception3b: torch.Size([32, 480, 28, 28])\n",
            "inception4a: torch.Size([32, 512, 14, 14])\n",
            "inception4b: torch.Size([32, 512, 14, 14])\n",
            "inception4c: torch.Size([32, 512, 14, 14])\n",
            "inception4d: torch.Size([32, 528, 14, 14])\n",
            "inception4e: torch.Size([32, 832, 14, 14])\n",
            "inception4_pool: torch.Size([32, 832, 7, 7])\n",
            "inception5a: torch.Size([32, 832, 7, 7])\n",
            "inception5b: torch.Size([32, 1024, 7, 7])\n",
            "inception5_pool: torch.Size([32, 1024, 1, 1])\n",
            "fc1: torch.Size([32, 1000])\n",
            "fc2: torch.Size([32, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0336, -0.0138, -0.0359,  ...,  0.0172,  0.0255,  0.0171],\n",
              "        [ 0.0336, -0.0138, -0.0359,  ...,  0.0172,  0.0255,  0.0171],\n",
              "        [ 0.0336, -0.0138, -0.0359,  ...,  0.0172,  0.0255,  0.0171],\n",
              "        ...,\n",
              "        [ 0.0336, -0.0138, -0.0359,  ...,  0.0172,  0.0255,  0.0171],\n",
              "        [ 0.0336, -0.0138, -0.0359,  ...,  0.0172,  0.0255,  0.0171],\n",
              "        [ 0.0336, -0.0138, -0.0359,  ...,  0.0172,  0.0255,  0.0171]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}