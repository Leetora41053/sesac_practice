{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTYEu/PX0QqydLUkb1SRgv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leetora41053/sesac_practice/blob/main/11_27_Convolutional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.optim import SGD"
      ],
      "metadata": {
        "id": "2971cN-hlUpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c_UkLDIUYtF"
      },
      "outputs": [],
      "source": [
        "'''원본'''\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "    self.conv1_act = nn.Tanh()\n",
        "    self.avg1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
        "    self.conv2_act = nn.Tanh()\n",
        "    self.avg2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
        "    self.conv3_act = nn.Tanh()\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
        "    self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv1_act(x)\n",
        "    x = self.avg1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv2_act(x)\n",
        "    x = self.avg2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv3_act(x)#(B, 120, 1, 1)-> (120, B*1*1)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "\n",
        "    x = self.fc1(x) # in_features: 채널 수 * 행 * 열\n",
        "    x = self.fc2(x)\n",
        "    #Cross Entropy의 loss_function에서 해주기 때문에 괜찮다\n",
        "    return x\n",
        "\n",
        "a = LeNet\n",
        "#모델링 후 randn으로 input shape를 만들고 레이어를 통과할 때마다 torch shape를 뽑아낸다\n",
        "#input tensor를 해서 스스로 맞는지 검증까지 거친다"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''nn.Seqeuntial'''\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
        "        nn.Tanh(),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "        nn.Tanh(),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "        nn.Tanh()\n",
        "        )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Linear(in_features=120, out_features=84),\n",
        "        nn.Linear(84, 10))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.layer2(x)\n",
        "    return x\n",
        "\n",
        "#모델링 후 randn으로 input shape를 만들고 레이어를 통과할 때마다 torch shape를 뽑아낸다\n",
        "#input tensor를 해서 스스로 맞는지 검증까지 거친다"
      ],
      "metadata": {
        "id": "IEkm-gxBLpOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''Model Testing'''\n",
        "\n",
        "#BCHW 순서\n",
        "test1 = torch.randn((10, 1, 28, 28))\n",
        "\n",
        "model = LeNet()\n",
        "\n",
        "out1 = model.forward(test1)\n",
        "\n",
        "out1.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-lQJ1TplDIU",
        "outputId": "1a024426-f50e-49a8-feaa-eddfc124bf8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "'''MNIST'''\n",
        "\n",
        "dataset = MNIST(root='data', train=True, download=True)\n",
        "\n",
        "for img, label in dataset:\n",
        "  print(type(img))\n",
        "  print(type(label))\n",
        "  img = np.array(img)\n",
        "\n",
        "  print(img.shape, img.dtype)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuvDanjrn6Nf",
        "outputId": "322190d1-3ab7-464a-e78d-264e49d2f512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "<class 'int'>\n",
            "(28, 28) uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset = MNIST(root='data', train=True, download=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "for img, label in dataset:\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "1pyq1Zqvy6XI",
        "outputId": "55071620-8a57-487f-c8fd-c9a6d06b9553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 28\n",
        "\n",
        "dataset = MNIST(root='data', train=True, download=True, transform=ToTensor())\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "n_sample = len(dataset)\n",
        "\n",
        "print(n_sample) #데이터에 들어가는 전체 샘플의 개수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwN_z2Hvxzd8",
        "outputId": "3d359b38-d0fe-44f4-9cfb-65ea55529f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.003\n",
        "EPOCHS = 10\n",
        "\n",
        "if torch.cuda.is_available(): DEVICE = 'cuda'\n",
        "elif torch.backends.mps.is_available(): DEVICE = 'mps'\n",
        "else: DEVICE = 'cpu'\n",
        "\n",
        "model = LeNet().to(DEVICE)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=LR)\n",
        "\n",
        "losses, accs = [], []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss, n_corrects = 0., 0\n",
        "    for X_, y_ in tqdm(dataloader):\n",
        "        X_, y_ = X_.to(DEVICE), y_.to(DEVICE)\n",
        "        # X_ = X_.reshape(BATCH_SIZE, -1) #Linear 선형 모델에서는 일자로 맞춰줘야 하지만 CNN은 넣기만 하면 알아서 계산해줌\n",
        "\n",
        "        pred = model(X_)\n",
        "        loss = loss_function(pred, y_)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * len(X_)\n",
        "        n_corrects += (torch.max(pred, axis=1)[1] == y_).sum().item()\n",
        "\n",
        "    epoch_loss /= n_sample\n",
        "    losses.append(epoch_loss)\n",
        "\n",
        "    epoch_acc = n_corrects / n_sample\n",
        "    accs.append(epoch_acc)\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}\")\n",
        "    print(f\"Loss: {epoch_loss: .4f}, Acc: {epoch_acc: .4f}\")\n",
        "\n",
        "## nn.Sequential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huk65T27zVS5",
        "outputId": "07e19b2f-ab91-4f27-9ee9-2d78192d89c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:32<00:00, 66.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Loss:  2.0794, Acc:  0.3771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:34<00:00, 62.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2\n",
            "Loss:  0.8099, Acc:  0.7732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:31<00:00, 67.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3\n",
            "Loss:  0.4569, Acc:  0.8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:34<00:00, 61.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4\n",
            "Loss:  0.3677, Acc:  0.8930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:33<00:00, 63.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5\n",
            "Loss:  0.3215, Acc:  0.9056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:33<00:00, 64.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6\n",
            "Loss:  0.2874, Acc:  0.9152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:37<00:00, 57.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7\n",
            "Loss:  0.2589, Acc:  0.9232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:32<00:00, 65.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8\n",
            "Loss:  0.2343, Acc:  0.9300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:31<00:00, 67.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9\n",
            "Loss:  0.2131, Acc:  0.9364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2143/2143 [00:34<00:00, 62.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10\n",
            "Loss:  0.1947, Acc:  0.9419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG Model"
      ],
      "metadata": {
        "id": "N1Ju1PSof0jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H, W = 224, 224\n",
        "input_tensor = torch.randn(size=(8, 3, H, W))\n",
        "\n",
        "class VGGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGNet, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=512*7*7, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(in_features=4096, out_features=1000))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "        # (b, c, h, w)\n",
        "      # torch.view(1차원, 2차원)\n",
        "        x = x.view(x.size(0), -1)\n",
        "      # mlp (b, w) -> (b, 512*7*7)\n",
        "        x = self.classifier(x)\n",
        "        #Cross Entropy의 loss_function에서 해주기 때문에 softmax가 없어도 괜찮음\n",
        "        return x\n",
        "\n",
        "\n",
        "model = VGGNet()\n",
        "model.forward(input_tensor)\n",
        "\n",
        "\n",
        "#모델링 후 randn으로 input shape를 만들고 레이어를 통과할 때마다 torch shape를 뽑아낸다\n",
        "#input tensor를 해서 스스로 맞는지 검증까지 거친다"
      ],
      "metadata": {
        "id": "wBUX3RzAfezL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb90001-59cd-45ad-b789-59c58bd417ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0090,  0.0099,  0.0073,  ..., -0.0044,  0.0108,  0.0137],\n",
              "        [-0.0090,  0.0099,  0.0073,  ..., -0.0044,  0.0107,  0.0137],\n",
              "        [-0.0090,  0.0099,  0.0073,  ..., -0.0044,  0.0107,  0.0137],\n",
              "        ...,\n",
              "        [-0.0091,  0.0099,  0.0073,  ..., -0.0044,  0.0107,  0.0137],\n",
              "        [-0.0090,  0.0099,  0.0073,  ..., -0.0044,  0.0107,  0.0137],\n",
              "        [-0.0090,  0.0099,  0.0073,  ..., -0.0044,  0.0107,  0.0137]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    }
  ]
}